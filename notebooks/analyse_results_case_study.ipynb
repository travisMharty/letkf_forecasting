{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import importlib\n",
    "\n",
    "from letkf_forecasting import analyse_results, letkf_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(analyse_results)\n",
    "importlib.reload(letkf_io)\n",
    "\n",
    "base_folder = '/a2/uaren/travis'\n",
    "\n",
    "decimals = 2\n",
    "\n",
    "year = 2014\n",
    "\n",
    "# month = 4\n",
    "# day = 15\n",
    "# day_name = 'translation'\n",
    "\n",
    "# month = 5\n",
    "# day = 29\n",
    "# day_name = 'more_complex'\n",
    "\n",
    "month = 4\n",
    "day = 26\n",
    "day_name = 'two_levels'\n",
    "\n",
    "dates = [datetime.date(2014, month, day)]\n",
    "runs = ['owp_opt', 'persistence', 'opt_flow', 'wrf_no_div', 'wrf_mean', 'radiosonde']\n",
    "# runs = [ 'owp_opt', 'persistence', 'opt_flow', 'wrf_no_div',\n",
    "#         'opt_flow_with_div', 'wrf', 'radiosonde', 'wrf_mean']\n",
    "# runs = ['wrf_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = \"/home2/travis/python_code/letkf_forecasting/tables/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "horizons = [15, 30, 45, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_dict = {'opt_flow': 'Opt.~Flow', \n",
    "               'opt_flow_with_div': 'Opt. Flow w/ Div.',\n",
    "               'wrf_no_div': 'NWP Winds',\n",
    "               'wrf': 'NWP w/ Div.',\n",
    "               'owp_opt': 'ANOC',                                                                                \n",
    "               'persistence': 'Persis.',\n",
    "               'radiosonde': 'Radiosonde',\n",
    "               'wrf_mean': 'NWP Avg.~Winds',\n",
    "               'ens_member': 'Ens.~Member'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = pd.DataFrame(index=horizons, columns=runs)\n",
    "rmse.index.name = 'Horizon'\n",
    "correlation = rmse.copy()\n",
    "bias = rmse.copy()\n",
    "for run_name in runs:\n",
    "    results_folder_path = os.path.join(                                          \n",
    "        base_folder,                                                               \n",
    "        'results',                                                               \n",
    "        f'{year:04}',                                                            \n",
    "        f'{month:02}',                                                           \n",
    "        f'{day:02}',                                                             \n",
    "        run_name)\n",
    "    results_folder_path = letkf_io.find_latest_run(results_folder_path)\n",
    "    results_folder_path = os.path.join(results_folder_path, 'single_day')\n",
    "    \n",
    "    stat_name = 'rmse'\n",
    "    file_path = os.path.join(results_folder_path,\n",
    "                             f'{stat_name}.h5')\n",
    "    rmse[run_name] = pd.read_hdf(file_path, stat_name)\n",
    "    \n",
    "    stat_name = 'bias'\n",
    "    file_path = os.path.join(results_folder_path,\n",
    "                             f'{stat_name}.h5')\n",
    "    bias[run_name] = pd.read_hdf(file_path, stat_name)\n",
    "    \n",
    "    stat_name = 'correlation'\n",
    "    file_path = os.path.join(results_folder_path,\n",
    "                             f'{stat_name}.h5')\n",
    "    correlation[run_name] = pd.read_hdf(file_path, stat_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "peices = [rmse, correlation, bias]\n",
    "combined = pd.concat(peices, axis=0,\n",
    "                     keys=['RMSE', 'Corr.', 'Bias'])\n",
    "combined = combined.rename(columns=legend_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_empty(str):\n",
    "    return str != ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_table(text, header_num=5, footer_num=2):\n",
    "    text = text.split(' ')\n",
    "    text = list(filter(is_empty, text))\n",
    "    text = ' '.join(text)\n",
    "    split_text = text.split('\\n')\n",
    "    split_titles2 = split_text[2]\n",
    "    removed = split_titles2[-2:]\n",
    "    split_titles2 = split_titles2[:-2]\n",
    "    split_titles2 = split_titles2.split('&')\n",
    "    for count, this in enumerate(split_titles2):\n",
    "        if len(this) > 2:\n",
    "            this = this[0] + '{' + this[1:-1] + '}' + this[-1]\n",
    "            split_titles2[count] = this\n",
    "    split_text[2] = '&'.join(split_titles2) + removed\n",
    "#     split_titles2 = split_text[2].split('&')\n",
    "#     split_titles3 = split_text[3].split('&')\n",
    "#     for num, title in enumerate(split_text[2].split('&')):\n",
    "#         if ' w/ Div.' in title:\n",
    "#             split_titles2[num] = title[:-8]\n",
    "#             split_titles3[num] = title[-9:]\n",
    "#     split_titles2 = '&'.join(split_titles2)\n",
    "#     split_titles3 = '&'.join(split_titles3)\n",
    "#     split_text[2] = split_titles2\n",
    "#     split_text[3] = split_titles3\n",
    "    \n",
    "    for line_num, line in enumerate(split_text[header_num:-footer_num - 1]):\n",
    "        split_line = line.split(' ')\n",
    "        if split_line[0] == 'Corr.':\n",
    "            Corr = True\n",
    "        elif split_line[0] != '':\n",
    "            Corr = False\n",
    "        num_slice = slice(4, None, 2)\n",
    "        numbers_str = split_line[num_slice]\n",
    "        numbers = np.array(\n",
    "            split_line[num_slice],\n",
    "            dtype='float')\n",
    "        if Corr:\n",
    "            best_num = numbers.max()\n",
    "        else:\n",
    "            best_num = numbers[np.abs(numbers).argmin()]\n",
    "        argmins = np.where(numbers == best_num)[0]\n",
    "#         numbers = list(numbers.astype('str'))\n",
    "        for argmin in argmins:\n",
    "            numbers_str[argmin] = '\\\\B ' + numbers_str[argmin]\n",
    "#             numbers_str[argmin] = '\\\\textbf{' + numbers_str[argmin] + '}'\n",
    "        split_line[num_slice] = numbers_str\n",
    "        split_text[header_num + line_num] = ' '.join(split_line)\n",
    "    \n",
    "#     for count in range(hor_num - 1):\n",
    "#         split_line.insert(((count + 1)*run_num)*2 + 2 + count, '&')\n",
    "#     split_line\n",
    "\n",
    "    \n",
    "    return '\\n'.join(split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llS[table-format=-1.3]S[table-format=-1.3]S[table-format=-1.3]S[table-format=-1.3]S[table-format=-1.3]S[table-format=-1.3]}\n",
      "\\toprule\n",
      " & & {ANOC} & {Persis.} & {Opt.~Flow} & {NWP Winds} & {NWP Avg.~Winds} & {Radiosonde} \\\\\n",
      "{} & Horizon & & & & & & \\\\\n",
      "\\midrule\n",
      "RMSE & 15 & \\B 0.23 & 0.24 & \\B 0.23 & 0.30 & 0.29 & 0.36 \\\\\n",
      " & 30 & \\B 0.28 & 0.32 & 0.29 & 0.40 & 0.38 & 0.39 \\\\\n",
      " & 45 & \\B 0.29 & 0.37 & 0.34 & 0.40 & 0.41 & 0.37 \\\\\n",
      " & 60 & \\B 0.29 & 0.38 & 0.35 & 0.39 & 0.39 & 0.35 \\\\\n",
      "Corr. & 15 & \\B 0.76 & 0.73 & 0.75 & 0.61 & 0.63 & 0.40 \\\\\n",
      " & 30 & \\B 0.63 & 0.52 & 0.62 & 0.24 & 0.32 & 0.24 \\\\\n",
      " & 45 & \\B 0.60 & 0.36 & 0.48 & 0.18 & 0.16 & 0.28 \\\\\n",
      " & 60 & \\B 0.60 & 0.35 & 0.49 & 0.23 & 0.27 & 0.40 \\\\\n",
      "Bias & 15 & -0.02 & \\B 0.01 & 0.02 & -0.10 & -0.08 & -0.10 \\\\\n",
      " & 30 & -0.03 & \\B 0.01 & 0.04 & -0.12 & -0.10 & -0.04 \\\\\n",
      " & 45 & -0.04 & \\B 0.00 & 0.04 & -0.11 & -0.10 & 0.01 \\\\\n",
      " & 60 & -0.07 & -0.03 & 0.02 & -0.09 & -0.07 & \\B -0.01 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "column_format = 'll' + 'S[table-format=-1.3]' * len(runs)\n",
    "text = combined.round(decimals=decimals).to_latex(column_format=column_format)\n",
    "text2 = format_table(text)\n",
    "text2 = re.sub('\\\\\\\\textasciitilde', '~', text2, count=5)\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_file = os.path.join(save_directory, f'{day_name}_results.tex')\n",
    "with open(this_file, 'w') as file:\n",
    "    file.write(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
