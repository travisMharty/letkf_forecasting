{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage.filters as filters\n",
    "from distributed import LocalCluster, Client\n",
    "from netCDF4 import Dataset, date2num, num2date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as time_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import letkf_forecasting.letkf_forecasting as lf\n",
    "import letkf_forecasting.prepare_sat_data as prep\n",
    "import letkf_forecasting.random_functions as rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_data = pd.read_hdf('/home/travis/python_code/letkf_forecasting_other_things/data/sensor_data.h5')\n",
    "sensor_CI = pd.read_hdf('/home/travis/python_code/letkf_forecasting_other_things/data/sensor_CI.h5')\n",
    "sensor_loc = pd.read_hdf('/home/travis/python_code/letkf_forecasting_other_things/data/sensor_loc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_loc.sort_values(by='id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = 5\n",
    "day = 29\n",
    "suffix = '_{month}_{day}'.format(month=month, day=day)\n",
    "file = '/home/travis/python_code/letkf_forecasting_other_things/data/for' + suffix + '/' + '{var}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "csi = pd.read_hdf(file.format(var='csi.h5'))\n",
    "x_sat = np.load(file.format(var='x.npy'))\n",
    "y_sat = np.load(file.format(var='y.npy'))\n",
    "domain_shape = np.load(file.format(var='domain_shape.npy'))\n",
    "U = pd.read_hdf(file.format(var='U.h5'))\n",
    "V = pd.read_hdf(file.format(var='V.h5'))\n",
    "U_shape = np.load(file.format(var='U_shape.npy'))\n",
    "V_shape = np.load(file.format(var='V_shape.npy'))\n",
    "\n",
    "U.index = U.index.tz_convert('MST')\n",
    "V.index = V.index.tz_convert('MST')\n",
    "csi.index = csi.index.tz_convert('MST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 2088025)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csi.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter winds\n",
    "filter_len = 30*4\n",
    "U_smooth = U.values.reshape(\n",
    "    [U.shape[0], U_shape[0], U_shape[1]])\n",
    "U_smooth = filters.uniform_filter(\n",
    "    U_smooth, size=(0, filter_len, filter_len))\n",
    "this_shape = U_smooth.shape\n",
    "U_smooth = U_smooth.reshape(this_shape[0], this_shape[1]*this_shape[2])\n",
    "U_smooth = pd.DataFrame(data=U_smooth, index=U.index)\n",
    "\n",
    "V_smooth = V.values.reshape(\n",
    "    [V.shape[0], V_shape[0], V_shape[1]])\n",
    "V_smooth = filters.uniform_filter(\n",
    "    V_smooth, size=(0, filter_len, filter_len))\n",
    "this_shape = V_smooth.shape\n",
    "V_smooth = V_smooth.reshape(this_shape[0], this_shape[1]*this_shape[2])\n",
    "V_smooth = pd.DataFrame(data=V_smooth, index=V.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = x_sat\n",
    "y_range = y_sat\n",
    "x_sat, y_sat = np.meshgrid(x_sat, y_sat)\n",
    "x_sat = x_sat.ravel()\n",
    "y_sat = y_sat.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_sens = sensor_loc['lon'].values\n",
    "lat_sens = sensor_loc['lat'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sens, y_sens = prep.sphere_to_lcc(lat_sens, lon_sens)\n",
    "x_min = np.floor(x_sens.min())\n",
    "x_max = np.ceil(x_sens.max())\n",
    "y_min = np.floor(y_sens.min())\n",
    "y_max = np.ceil(y_sens.max())\n",
    "west_east_min = np.argmin(abs(x_min - x_range))\n",
    "west_east_max = np.argmin(abs(x_max - x_range))\n",
    "south_north_min = np.argmin(abs(y_min - y_range))\n",
    "south_north_max = np.argmin(abs(y_max - y_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# side_length = 800 # 200 km\n",
    "# we_width = west_east_max - west_east_min\n",
    "# if we_width%2 != 0:\n",
    "#     west_east_min -= 1\n",
    "#     we_width = west_east_max - west_east_min\n",
    "# we_border = (side_length - we_width)/2\n",
    "# left = west_east_min - we_border\n",
    "# right = west_east_max + we_border + 1\n",
    "# west_east_range = np.arange(left, right, dtype='int')\n",
    "# west_east_range_stag = np.arange(left, right + 1, dtype='int')\n",
    "\n",
    "\n",
    "# sn_width = south_north_max - south_north_min\n",
    "# if sn_width%2 != 0:\n",
    "#     south_north_min -= 1\n",
    "#     sn_width = south_north_max - south_north_min\n",
    "# sn_border = (side_length - sn_width)/2\n",
    "# down = int(round(south_north_min - sn_border))\n",
    "# up = int(round(south_north_max + sn_border + 1))\n",
    "# south_north_range = np.arange(down, up, dtype='int')\n",
    "# south_north_range_stag = np.arange(down, up + 1, dtype='int')\n",
    "\n",
    "# crop_shape = (south_north_range.size, west_east_range.size)\n",
    "# U_crop_shape = (south_north_range.size, west_east_range_stag.size)\n",
    "# V_crop_shape = (south_north_range_stag.size, west_east_range.size)\n",
    "# print('X length: ' + \n",
    "#       str(west_east_range.size))\n",
    "# print('Y length: ' + \n",
    "#       str(south_north_range.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X length: 374\n",
      "Y length: 654\n"
     ]
    }
   ],
   "source": [
    "# max_forecast = 45\n",
    "max_forecast = 60\n",
    "if U.values.mean()>0:\n",
    "    U_max = U.values.max() # know U is positive\n",
    "    left = int(U_max*60*max_forecast/250) + 10\n",
    "    right = 10\n",
    "else:\n",
    "    U_min = U.values.min() # know U is negative\n",
    "    left = 10\n",
    "    right = int(abs(U_min)*60*max_forecast/250) + 10\n",
    "\n",
    "if V.values.mean()>0:  \n",
    "    V_max = V.values.max() # know V is positive\n",
    "    down = int(V_max*60*max_forecast/250) + 10\n",
    "    up = 10\n",
    "else:\n",
    "    V_min = V.values.min()\n",
    "    down = 10\n",
    "    up = int(abs(V_min)*60*max_forecast/250) + 10\n",
    "\n",
    "west_east_range = np.arange(west_east_min - left, west_east_max + right + 1, dtype='int')\n",
    "west_east_range_stag = np.arange(west_east_min - left, west_east_max + right + 1 + 1, dtype='int')\n",
    "south_north_range = np.arange(south_north_min - down, south_north_max + up + 1, dtype='int')\n",
    "south_north_range_stag = np.arange(south_north_min - down, south_north_max + up + 1 + 1, dtype='int')\n",
    "crop_shape = (south_north_range.size, west_east_range.size)\n",
    "U_crop_shape = (south_north_range.size, west_east_range_stag.size)\n",
    "V_crop_shape = (south_north_range_stag.size, west_east_range.size)\n",
    "U_crop_size = U_crop_shape[0]*U_crop_shape[1]\n",
    "V_crop_size = V_crop_shape[0]*V_crop_shape[1]\n",
    "print('X length: ' + \n",
    "      str(west_east_range.size))\n",
    "print('Y length: ' + \n",
    "      str(south_north_range.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "west_east_crop, south_north_crop = np.meshgrid(west_east_range, south_north_range)\n",
    "crop_indicies_2d = np.array([south_north_crop.ravel(),\n",
    "                             west_east_crop.ravel()])\n",
    "flat_crop_indicies = np.ravel_multi_index(crop_indicies_2d,\n",
    "                                          domain_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "west_east_crop_U, south_north_crop_U = np.meshgrid(west_east_range_stag, south_north_range)\n",
    "crop_indicies_2d_U = np.array([south_north_crop_U.ravel(),\n",
    "                               west_east_crop_U.ravel()])\n",
    "flat_crop_indicies_U = np.ravel_multi_index(crop_indicies_2d_U,\n",
    "                                            U_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "west_east_crop_V, south_north_crop_V = np.meshgrid(west_east_range, south_north_range_stag)\n",
    "crop_indicies_2d_V = np.array([south_north_crop_V.ravel(),\n",
    "                               west_east_crop_V.ravel()])\n",
    "flat_crop_indicies_V = np.ravel_multi_index(crop_indicies_2d_V,\n",
    "                                            V_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_crop = x_sat[flat_crop_indicies]\n",
    "y_crop = y_sat[flat_crop_indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_crop_range = x_crop.reshape(crop_shape)[0, :]\n",
    "y_crop_range = y_crop.reshape(crop_shape)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X length: 177\n",
      "Y length: 241\n"
     ]
    }
   ],
   "source": [
    "west_east_min = np.argmin(abs(x_min - x_crop_range))\n",
    "west_east_max = np.argmin(abs(x_max - x_crop_range))\n",
    "south_north_min = np.argmin(abs(y_min - y_crop_range))\n",
    "south_north_max = np.argmin(abs(y_max - y_crop_range))\n",
    "we_error_range = np.arange(west_east_min - 8, west_east_max + 9, dtype='int')\n",
    "sn_error_range = np.arange(south_north_min - 8, south_north_max + 9, dtype='int')\n",
    "error_domain_shape = (sn_error_range.size, we_error_range.size)\n",
    "print('X length: ' + \n",
    "      str(we_error_range.size))\n",
    "print('Y length: ' + \n",
    "      str(sn_error_range.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "west_east_error_crop, south_north_error_crop = np.meshgrid(\n",
    "    we_error_range, sn_error_range)\n",
    "crop_indicies_2d_error = np.array([south_north_error_crop.ravel(),\n",
    "                             west_east_error_crop.ravel()])\n",
    "flat_error_domain = np.ravel_multi_index(crop_indicies_2d_error,\n",
    "                                         crop_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "csi_crop = csi[flat_crop_indicies]\n",
    "csi_crop.columns = np.arange(flat_crop_indicies.size, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_crop = U_smooth[flat_crop_indicies_U]\n",
    "U_crop.columns = np.arange(flat_crop_indicies_U.size, dtype='int')\n",
    "V_crop = V_smooth[flat_crop_indicies_V]\n",
    "V_crop.columns = np.arange(flat_crop_indicies_V.size, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(rf)\n",
    "Lx = 5 # 2.5 # 10 # 1\n",
    "Ly = 5 # 2.5 # 10 # 1\n",
    "tol = 0.005\n",
    "rf_eig, rf_vectors = rf.eig_2d_covariance(\n",
    "    x=x_crop_range, y=y_crop_range,\n",
    "    Lx=Lx, Ly=Ly, tol=tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_var = (rf_vectors*rf_eig[None, :]*rf_vectors).sum(-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('./data/random_fun/e', e)\n",
    "# np.save('./data/random_fun/v', v)\n",
    "# np.save('./data/random_fun/approx_var', approx_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e = np.load('./data/random_fun/e.npy')\n",
    "# v = np.load('./data/random_fun/v.npy')\n",
    "# approx_var = np.load('./data/random_fun/approx_var.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# n_workers = 20\n",
    "# cluster = LocalCluster(n_workers=n_workers, scheduler_port=7001, diagnostics_port=7002)\n",
    "# client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving winds and satellite data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make file paths\n",
    "# this_date = csi.index[0].date()\n",
    "# year = this_date.year\n",
    "# month = this_date.month\n",
    "# day = this_date.day\n",
    "\n",
    "year = 2014\n",
    "month = 5\n",
    "day = 29\n",
    "\n",
    "home = os.path.expanduser(\"~\")\n",
    "file_path = f'{home}/data/{year:04}/{month:02}/{day:02}/'\n",
    "if not os.path.exists(file_path):\n",
    "    os.makedirs(file_path)\n",
    "    \n",
    "file_path_ci = os.path.join(file_path, 'ci.h5')\n",
    "print(file_path_ci)\n",
    "file_path_winds = os.path.join(file_path, 'winds.h5')\n",
    "print(file_path_winds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home2/travis/data/2014/05/29/data.nc\n"
     ]
    }
   ],
   "source": [
    "# make file paths\n",
    "# this_date = csi.index[0].date()\n",
    "# year = this_date.year\n",
    "# month = this_date.month\n",
    "# day = this_date.day\n",
    "\n",
    "year = 2014\n",
    "month = 5\n",
    "day = 29\n",
    "\n",
    "home = os.path.expanduser(\"~\")\n",
    "file_path = f'{home}/data/{year:04}/{month:02}/{day:02}/'\n",
    "if not os.path.exists(file_path):\n",
    "    os.makedirs(file_path)\n",
    "    \n",
    "file_path_store = os.path.join(file_path, 'data.nc')\n",
    "print(file_path_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape everything back again\n",
    "x = x_sat.reshape(domain_shape)[0, :]\n",
    "y = y_sat.reshape(domain_shape)[:, 0]\n",
    "time = csi.index.tz_convert('UTC').tz_convert(None).to_pydatetime()\n",
    "time = date2num(time, 'seconds since 1970-1-1')\n",
    "ci = csi.values.reshape([time.size, domain_shape[0], domain_shape[1]])\n",
    "time_wind = U.index.tz_convert('UTC').tz_convert(None).to_pydatetime()\n",
    "time_wind = date2num(time_wind, 'seconds since 1970-1-1')\n",
    "U_reshape = U.values.reshape(wind_time.size, U_shape[0], U_shape[1])\n",
    "V_reshape = V.values.reshape(wind_time.size, V_shape[0], V_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = (x[1] - x[0])\n",
    "x_stag = np.concatenate([x - dx/2, [x[-1] + dx/2]])\n",
    "dy = (y[1] - y[0])\n",
    "y_stag = np.concatenate([y - dy/2, [y[-1] + dy/2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float64 west_east(west_east)\n",
      "unlimited dimensions: \n",
      "current shape = (1445,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "\n",
      "[-- -- -- ..., -- -- --]\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float64 west_east(west_east)\n",
      "unlimited dimensions: \n",
      "current shape = (1445,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "\n",
      "[  80.     80.25   80.5  ...,  440.5   440.75  441.  ]\n"
     ]
    }
   ],
   "source": [
    "# need more metadata here\n",
    "with Dataset(file_path_store, 'w') as store:\n",
    "    store.createDimension('west_east', size=x.size)\n",
    "    store.createDimension('south_north', size=y.size)\n",
    "    store.createDimension('we_stag', size=x_stag.size)\n",
    "    store.createDimension('sn_stag', size=y_stag.size)\n",
    "    store.createDimension('time', size=time.size)\n",
    "    store.createDimension('time_wind', size=wind_time.size)\n",
    "    wenc = store.createVariable('west_east', 'f8', ('west_east',), zlib=True)\n",
    "    snnc = store.createVariable('south_north', 'f8', ('south_north',), zlib=True)\n",
    "    we_stagnc = store.createVariable('we_stag', 'f8', ('we_stag',), zlib=True)\n",
    "    sn_stagnc = store.createVariable('sn_stag', 'f8', ('sn_stag',), zlib=True)\n",
    "    timenc = store.createVariable('time', 'f8', ('time',), zlib=True)\n",
    "    time_windnc = store.createVariable('time_wind', 'f8', ('time_wind',), zlib=True)\n",
    "    cinc = store.createVariable('ci', 'f8', ('time', 'south_north', 'west_east',), zlib=True)\n",
    "    Unc = store.createVariable('U', 'f8', ('time_wind', 'south_north', 'we_stag',), zlib=True)\n",
    "    Vnc = store.createVariable('V', 'f8', ('time_wind', 'sn_stag', 'west_east',), zlib=True)\n",
    "    wenc[:] = x\n",
    "    snnc[:] = y\n",
    "    we_stagnc[:] = x_stag\n",
    "    sn_stagnc[:] = y_stag\n",
    "    timenc[:] = time\n",
    "    time_windnc[:] = time_wind\n",
    "    cinc[:] = ci\n",
    "    Unc[:] = U_reshape\n",
    "    Vnc[:] = V_reshape\n",
    "    timenc.units = 'seconds since 1970-1-1'\n",
    "    time_windnc.units = 'seconds since 1970-1-1'\n",
    "    # should move this into forecast_system with calculation\n",
    "    cinc.we_min_crop = west_east_range[0]\n",
    "    cinc.we_max_crop = west_east_range[-1]\n",
    "    cinc.sn_min_crop = south_north_range[0]\n",
    "    cinc.sn_max_crop = south_north_range[-1]\n",
    "    Unc.we_min_crop = west_east_range_stag[0]\n",
    "    Unc.we_max_crop = west_east_range_stag[-1]\n",
    "    Unc.sn_min_crop = south_north_range[0]\n",
    "    Unc.sn_max_crop = south_north_range[-1]\n",
    "    Vnc.we_min_crop = west_east_range[0]\n",
    "    Vnc.we_max_crop = west_east_range[-1]\n",
    "    Vnc.sn_min_crop = south_north_range_stag[0]\n",
    "    Vnc.sn_max_crop = south_north_range_stag[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dic = {\n",
    "    #data_paths\n",
    "    'data_file_path':file_path_store,\n",
    "    \n",
    "    #Switches\n",
    "    'assim_test':0,\n",
    "    'perturbation_test':0,\n",
    "    'div_test':0,\n",
    "    'assim_of_test':0,\n",
    "    'assim_sat2sat_test':0,\n",
    "    'assim_sat2wind_test':0,\n",
    "    'assim_wrf_test':0,\n",
    "    \n",
    "    #advection_params\n",
    "    'start_time':0,\n",
    "    'end_time':0,\n",
    "    'C_max':0.7,\n",
    "    'max_horizon': '1hour', # fix this in letkf_forecasting\n",
    "    'client_address': '127.0.0.1:8786',\n",
    "    \n",
    "    #assimilation_params\n",
    "    #assim_sat2sat\n",
    "    'sig_sat2sat' : 0.05,\n",
    "    'loc_sat2sat' : 1*4,\n",
    "    'infl_sat2sat' : 1.5,\n",
    "    'assim_gs_sat2sat':20, #if assim_sat is false, this is for sat into winds\n",
    "    #assim_sat2wind\n",
    "    'sig_sat2wind':1,\n",
    "    'loc_sat2wind':30*4,\n",
    "    'infl_sat2wind':4,\n",
    "    'assim_gs_sat2wind':20,\n",
    "    #assim_wrf\n",
    "    'sig_wrf':0.5,\n",
    "    'infl_wrf':1,\n",
    "    'loc_wrf':1*4,\n",
    "    'assim_gs_wrf':5,\n",
    "    #assim_OF\n",
    "    'sig_of':1,\n",
    "    'loc_of':20, #in km not grid spaces,\n",
    "    'infl_of':4, # 10 # was 1\n",
    "    \n",
    "    #ensemble_params\n",
    "    'ens_num':20,\n",
    "    'winds_sigma':(1, 1),\n",
    "    'ci_sigma':.4,\n",
    "    \n",
    "    #perturbation_params\n",
    "    'Lx':5,\n",
    "    'Ly':5,\n",
    "    'tol':0.005,\n",
    "    'pert_sigma':0.15/3,\n",
    "    'pert_mean':0,\n",
    "    'edge_weight':1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home2/travis/data/2014/05/29/data.nc\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import importlib\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage.filters as filters\n",
    "from distributed import LocalCluster, Client\n",
    "from netCDF4 import Dataset, date2num, num2date\n",
    "\n",
    "import time as time_py\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import letkf_forecasting.letkf_forecasting as lf\n",
    "import letkf_forecasting.prepare_sat_data as prep\n",
    "import letkf_forecasting.random_functions as rf\n",
    "\n",
    "\n",
    "year = 2014\n",
    "month = 5\n",
    "day = 29\n",
    "\n",
    "home = os.path.expanduser(\"~\")\n",
    "file_path = f'{home}/data/{year:04}/{month:02}/{day:02}/'\n",
    "if not os.path.exists(file_path):\n",
    "    os.makedirs(file_path)\n",
    "    \n",
    "file_path_store = os.path.join(file_path, 'data.nc')\n",
    "print(file_path_store)\n",
    "param_dic = {\n",
    "    #data_paths\n",
    "    'data_file_path':file_path_store,\n",
    "    \n",
    "    #Switches\n",
    "    'assim_test':1,\n",
    "    'perturbation_test':0,\n",
    "    'div_test':0,\n",
    "    'assim_of_test':0,\n",
    "    'assim_sat2sat_test':0,\n",
    "    'assim_sat2wind_test':0,\n",
    "    'assim_wrf_test':1,\n",
    "    \n",
    "    #advection_params\n",
    "    'start_time':0,\n",
    "    'end_time':0,\n",
    "    'C_max':0.7,\n",
    "    'max_horizon': '1hour', # fix this in letkf_forecasting\n",
    "    'client_address': '127.0.0.1:8786',\n",
    "    \n",
    "    #assimilation_params\n",
    "    #assim_sat2sat\n",
    "    'sig_sat2sat' : 0.05,\n",
    "    'loc_sat2sat' : 1*4,\n",
    "    'infl_sat2sat' : 1.5,\n",
    "    'assim_gs_sat2sat':20, #if assim_sat is false, this is for sat into winds\n",
    "    #assim_sat2wind\n",
    "    'sig_sat2wind':1,\n",
    "    'loc_sat2wind':30*4,\n",
    "    'infl_sat2wind':4,\n",
    "    'assim_gs_sat2wind':20,\n",
    "    #assim_wrf\n",
    "    'sig_wrf':0.5,\n",
    "    'infl_wrf':1,\n",
    "    'loc_wrf':1*4,\n",
    "    'assim_gs_wrf':5,\n",
    "    #assim_OF\n",
    "    'sig_of':1,\n",
    "    'loc_of':20, #in km not grid spaces,\n",
    "    'infl_of':4, # 10 # was 1\n",
    "    \n",
    "    #ensemble_params\n",
    "    'ens_num':20,\n",
    "    'winds_sigma':(1, 1),\n",
    "    'ci_sigma':.4,\n",
    "    \n",
    "    #perturbation_params\n",
    "    'Lx':5,\n",
    "    'Ly':5,\n",
    "    'tol':0.005,\n",
    "    'pert_sigma':0.15/3,\n",
    "    'pert_mean':0,\n",
    "    'edge_weight':1,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "this = pd.Timestamp('2001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "this = this.tz_localize('UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTC\n"
     ]
    }
   ],
   "source": [
    "print(this.tz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unsupported time units",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-b0cc95d7d673>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mthis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum2date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nanoseconds since 1970-1-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum2date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seconds since 1970-1-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.num2date\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unsupported time units"
     ]
    }
   ],
   "source": [
    "this = num2date([1, 2, 4], 'nanoseconds since 1970-1-1')\n",
    "that = num2date([1, 2, 3], 'seconds since 1970-1-1')\n",
    "pd.DatetimeIndex(this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['1970-01-01 00:00:00.000000001',\n",
       "               '1970-01-01 00:00:00.000000002',\n",
       "               '1970-01-01 00:00:00.000000004'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DatetimeIndex([1, 2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'datetime' from '/home/travis/miniconda3/envs/py36letkf/lib/python3.6/datetime.py'>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took: 50.166432809829715\n"
     ]
    }
   ],
   "source": [
    "# forecast_system\n",
    "importlib.reload(lf)\n",
    "time0 = time_py.time()\n",
    "importlib.reload(logging)\n",
    "logging.basicConfig(filename='/home2/travis/python_code/letkf_forecasting_other_things/logs/letkf.log', filemode='w', level=logging.DEBUG)\n",
    "logging.info('Started')\n",
    "\n",
    "returned = lf.forecast_system(param_dic, **param_dic)\n",
    "logging.info('Ended')\n",
    "time1 = time_py.time()\n",
    "print('It took: ' + str((time1 - time0)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244970"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "490220 - 654*375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490220"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "654*375 + 655*374"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.path.expanduser('~')                                                                                                                                                                                       \n",
    "run_num = 0                                                                                                                                                                                                          \n",
    "file_path_r = (f'{home}/results/{year:04}'                                                                                                                                                                           \n",
    "               f'/{month:02}/{day:02}')\n",
    "if not os.path.exists(file_path_r):                                                                                                                                                                                  \n",
    "    os.makedirs(file_path_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_r = os.path.join(file_path_r, 'test.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = Dataset(file_path_r, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.createGroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1 is True:\n",
    "    print('this')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make metadata should probably be more here: ci:interp method; winds: smoothing, level series\n",
    "ci_metadata = {'shape':domain_shape, 'crop_shape':crop_shape, 'dx':250, 'dy':250}\n",
    "u_metadata = {'shape':U_shape, 'crop_shape':U_crop_shape}\n",
    "v_metadata = {'shape':V_shape, 'crop_shape':V_crop_shape}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(file_path_ci, mode='w', complevel=4) as store:\n",
    "    store.put('ci', csi.T, format='table')\n",
    "    store.put('x', pd.Series(x_sat))\n",
    "    store.put('y', pd.Series(y_sat))\n",
    "    store.put('crop_cols', pd.Series(flat_crop_indicies))\n",
    "    store.put('metadata', pd.Series(ci_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(file_path_winds, mode='w', complevel=4) as store:\n",
    "    store.put('U', U_smooth.T, format='table')\n",
    "    store.put('V', V_smooth.T, format='table')\n",
    "    store.put('U_crop_cols', pd.Series(flat_crop_indicies_U))\n",
    "    store.put('V_crop_cols', pd.Series(flat_crop_indicies_V))\n",
    "    store.put('U_metadata', pd.Series(u_metadata))\n",
    "    store.put('V_metadata', pd.Series(v_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(file_path_ci, mode='r', complevel=4) as store:\n",
    "    this = np.array(store.select(\n",
    "        'ci', columns=[this_date], where=['index=flat_crop_indicies']))\n",
    "    plt.figure()\n",
    "    plt.pcolormesh((this.reshape(crop_shape)), cmap='Blues')\n",
    "    plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ravel_multi_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " s = (f\"this is {a} very\"\n",
    "      f\"long stri{a}ng too\"\n",
    "      \"for sure ...\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore('/home2/travis/results/2014/05/29/run000/results.h5') as store:\n",
    "#     print(store)\n",
    "    print(store['param_dic'])\n",
    "    this = store['MST1215_ci']\n",
    "    for col in this.columns:\n",
    "        plt.figure()\n",
    "        plt.pcolormesh(this[col].reshape(crop_shape), cmap='Blues')\n",
    "        plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.put('ensemble_15', ensemble_15)\n",
    "store.put('ensemble_30', ensemble_30)\n",
    "store.put('ensemble_45', ensemble_45)\n",
    "store.put('ensemble_60', ensemble_60)\n",
    "store.put('ensemble_analy', ensemble_analy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_15.to_hdf('./results/letkf_wind_2/ensemble_15.h5', 'ensemble_15', complevel=4)\n",
    "ensemble_30.to_hdf('./results/letkf_wind_2/ensemble_30.h5', 'ensemble_30', complevel=4)\n",
    "ensemble_45.to_hdf('./results/letkf_wind_2/ensemble_45.h5', 'ensemble_45', complevel=4)\n",
    "ensemble_60.to_hdf('./results/letkf_wind_2/ensemble_45.h5', 'ensemble_60', complevel=4)\n",
    "ensemble_analy.to_hdf('./results/letkf_wind_2/ensemble_analy.h5', 'ensemble_analy', complevel=4)    \n",
    "# advected_15.to_hdf('./results/letkf_wind_2/advected_15.h5', 'advected_15')\n",
    "# advected_30.to_hdf('./results/letkf_wind_2/advected_30.h5', 'advected_30')\n",
    "# advected_45.to_hdf('./results/letkf_wind_2/advected_45.h5', 'advected_45')\n",
    "np.save('./results/letkf_wind_2/ens_shape', ens_shape)\n",
    "np.save('./results/letkf_wind_2/param_dic', param_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "#     plt.figure()\n",
    "#     plt.pcolormesh(csi.iloc[i][flat_crop_indicies].values.reshape(crop_shape))\n",
    "#     plt.axes().set_aspect('equal')\n",
    "\n",
    "#     plt.figure()\n",
    "#     im = plt.pcolormesh(U_smooth.iloc[i][flat_crop_indicies_U].values.reshape(U_crop_shape))\n",
    "#     plt.axes().set_aspect('equal')\n",
    "#     plt.colorbar(im)\n",
    "    \n",
    "    plt.figure()\n",
    "    im = plt.pcolormesh(V_smooth.iloc[i][flat_crop_indicies_V].values.reshape(V_crop_shape))\n",
    "    plt.axes().set_aspect('equal')\n",
    "    plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_15.to_hdf('./results/letkf_wind/ensemble_15.h5', 'ensemble_15')\n",
    "ensemble_30.to_hdf('./results/letkf_wind/ensemble_30.h5', 'ensemble_30')\n",
    "ensemble_45.to_hdf('./results/letkf_wind/ensemble_45.h5', 'ensemble_45')\n",
    "ensemble_analy.to_hdf('./results/letkf_wind/ensemble_analy.h5', 'ensemble_analy')    \n",
    "advected_15.to_hdf('./results/letkf_wind/advected_15.h5', 'advected_15')\n",
    "advected_30.to_hdf('./results/letkf_wind/advected_30.h5', 'advected_30')\n",
    "advected_45.to_hdf('./results/letkf_wind/advected_45.h5', 'advected_45')\n",
    "np.save('./results/letkf_wind/ens_shape', ens_shape)\n",
    "np.save('./results/letkf_wind/param_dic', param_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_15 = pd.read_hdf('./results/letkf_wind_long_bad/ensemble_15.h5', 'ensemble_15')\n",
    "ensemble_30 = pd.read_hdf('./results/letkf_wind_long_bad/ensemble_30.h5', 'ensemble_30')\n",
    "ensemble_45 = pd.read_hdf('./results/letkf_wind_long_bad/ensemble_45.h5', 'ensemble_45')\n",
    "ensemble_analy = pd.read_hdf('./results/letkf_wind_long_bad/ensemble_analy.h5', 'ensemble_analy')    \n",
    "advected_15 = pd.read_hdf('./results/letkf_wind_long_bad/advected_15.h5', 'advected_15')\n",
    "advected_30 = pd.read_hdf('./results/letkf_wind_long_bad/advected_30.h5', 'advected_30')\n",
    "advected_45 = pd.read_hdf('./results/letkf_wind_long_bad/advected_45.h5', 'advected_45')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_shape = (U_crop_shape[0], V_crop_shape[1])\n",
    "this_u = U_crop.iloc[0].values.reshape(U_crop_shape)\n",
    "this_v = V_crop.iloc[0].values.reshape(V_crop_shape)\n",
    "# lf.remove_divergence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_processing(ensemble, ens_shape, wind_size, error_indicies, truth):\n",
    "    ens_mean = ensemble.mean(axis=1)\n",
    "    ens_sd = np.sqrt(ensemble.var(axis=1))\n",
    "    ens_error = (ens_mean[wind_size:] - truth)\n",
    "    rmse = np.sqrt((ens_error[error_indicies]**2).mean())\n",
    "    sd = np.sqrt((ens_sd[error_indicies + wind_size]**2).mean())\n",
    "    sd_wind = None\n",
    "    if wind_size != 0:\n",
    "        sd_wind = np.sqrt((ens_sd[:wind_size]**2).mean())\n",
    "    return ens_mean, ens_sd, ens_error, rmse, sd, sd_wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## ensemble calculations:\n",
    "forecast_15_error = csi_crop.iloc[slice(1, None)]*np.nan\n",
    "forecast_30_error = forecast_15_error.copy()\n",
    "forecast_45_error = forecast_15_error.copy()\n",
    "index = forecast_15_error.index\n",
    "forecast_15_sd = pd.DataFrame(data=np.ones([index.size, ens_shape[0]])*np.nan,\n",
    "                              index=index)\n",
    "forecast_30_sd = forecast_15_sd.copy()\n",
    "forecast_45_sd = forecast_15_sd.copy()\n",
    "forecast_15 = forecast_15_sd.copy()\n",
    "forecast_30 = forecast_15_sd.copy()\n",
    "forecast_45 = forecast_15_sd.copy()\n",
    "analysis = forecast_15.copy()\n",
    "analysis_error = forecast_15_error.copy()\n",
    "analysis_sd = forecast_15_sd.copy()\n",
    "advected_15_error = forecast_15_error.copy()\n",
    "advected_30_error = forecast_15_error.copy()\n",
    "advected_45_error = forecast_15_error.copy()\n",
    "\n",
    "col_names = ['fore_15', 'advected_15', 'fore_sd_15', 'fore_wind_sd_15', \n",
    "             'fore_30', 'advected_30', 'fore_sd_30', 'fore_wind_sd_30', \n",
    "             'fore_45', 'advected_45', 'fore_sd_45', 'fore_wind_sd_45',\n",
    "             'analy', 'analy_sd', 'analy_wind_sd']                                                             \n",
    "error_stats = pd.DataFrame(data=np.ones(len(col_names))[None, :]*np.nan,                                                     \n",
    "                              index=[csi_crop.index[0]],                                                                        \n",
    "                              columns=col_names)\n",
    "wind_size = U_crop_size + V_crop_size\n",
    "for time in csi_crop.index[1:]:\n",
    "    sat = csi_crop.loc[time]\n",
    "    if time in ensemble_analy.index:\n",
    "        returned = ensemble_processing(\n",
    "            ensemble_analy.loc[time].values.reshape(ens_shape),\n",
    "            ens_shape, wind_size, flat_error_domain,\n",
    "            csi_crop.loc[time])\n",
    "        analysis.loc[time] = returned[0]\n",
    "        analysis_sd.loc[time] = returned[1]\n",
    "        analysis_error.loc[time] = returned[2]\n",
    "        \n",
    "        error_stats.loc[time, 'analy'] = returned[3]\n",
    "        error_stats.loc[time, 'analy_sd'] = returned[4]\n",
    "        error_stats.loc[time, 'analy_wind_sd'] = returned[5]\n",
    "    if time in ensemble_15.index:\n",
    "        returned = ensemble_processing(\n",
    "            ensemble_15.loc[time].values.reshape(ens_shape),\n",
    "            ens_shape, wind_size, flat_error_domain,\n",
    "            csi_crop.loc[time])\n",
    "        forecast_15.loc[time] = returned[0]\n",
    "        forecast_15_sd.loc[time] = returned[1]\n",
    "        forecast_15_error.loc[time] = returned[2]\n",
    "        \n",
    "        error_stats.loc[time, 'fore_15'] = returned[3]\n",
    "        error_stats.loc[time, 'fore_sd_15'] = returned[4]\n",
    "        error_stats.loc[time, 'fore_wind_sd_15'] = returned[5]\n",
    "        \n",
    "        advected_15_error.loc[time] = (\n",
    "            advected_15.loc[time].values - csi_crop.loc[time])\n",
    "        error_stats.loc[time, 'advected_15'] = np.sqrt(\n",
    "            (advected_15_error.loc[time]\n",
    "             .values[flat_error_domain]**2).mean())\n",
    "\n",
    "            \n",
    "    if time in ensemble_30.index:\n",
    "        returned = ensemble_processing(\n",
    "            ensemble_30.loc[time].values.reshape(ens_shape),\n",
    "            ens_shape, wind_size, flat_error_domain,\n",
    "            csi_crop.loc[time])\n",
    "        forecast_30.loc[time] = returned[0]\n",
    "        forecast_30_sd.loc[time] = returned[1]\n",
    "        forecast_30_error.loc[time] = returned[2]\n",
    "        \n",
    "        error_stats.loc[time, 'fore_30'] = returned[3]\n",
    "        error_stats.loc[time, 'fore_sd_30'] = returned[4]\n",
    "        error_stats.loc[time, 'fore_wind_sd_30'] = returned[5]\n",
    "        \n",
    "        advected_30_error.loc[time] = (\n",
    "            advected_30.loc[time].values - csi_crop.loc[time])\n",
    "        error_stats.loc[time, 'advected_30'] = np.sqrt(\n",
    "            (advected_30_error.loc[time]\n",
    "             .values[flat_error_domain]**2).mean())\n",
    "\n",
    "    \n",
    "    if time in ensemble_45.index:\n",
    "        returned = ensemble_processing(\n",
    "            ensemble_45.loc[time].values.reshape(ens_shape),\n",
    "            ens_shape, wind_size, flat_error_domain,\n",
    "            csi_crop.loc[time])\n",
    "        forecast_45.loc[time] = returned[0]\n",
    "        forecast_45_sd.loc[time] = returned[1]\n",
    "        forecast_45_error.loc[time] = returned[2]\n",
    "        \n",
    "        error_stats.loc[time, 'fore_45'] = returned[3]\n",
    "        error_stats.loc[time, 'fore_sd_45'] = returned[4]\n",
    "        error_stats.loc[time, 'fore_wind_sd_45'] = returned[5]\n",
    "        \n",
    "        advected_45_error.loc[time] = (\n",
    "            advected_45.loc[time].values - csi_crop.loc[time])\n",
    "        error_stats.loc[time, 'advected_45'] = np.sqrt(\n",
    "            (advected_45_error.loc[time]\n",
    "             .values[flat_error_domain]**2).mean())\n",
    "\n",
    "forecast_15.dropna(inplace=True)\n",
    "forecast_30.dropna(inplace=True)\n",
    "forecast_45.dropna(inplace=True)\n",
    "forecast_15_sd.dropna(inplace=True)\n",
    "forecast_30_sd.dropna(inplace=True)\n",
    "forecast_45_sd.dropna(inplace=True)\n",
    "forecast_15_error.dropna(inplace=True)\n",
    "forecast_30_error.dropna(inplace=True)\n",
    "forecast_45_error.dropna(inplace=True)\n",
    "analysis.dropna(inplace=True)\n",
    "analysis_error.dropna(inplace=True)\n",
    "analysis_sd.dropna(inplace=True)\n",
    "advected_15_error.dropna(inplace=True)\n",
    "advected_30_error.dropna(inplace=True)\n",
    "advected_45_error.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymax=None\n",
    "to_plot = ['fore_15', 'advected_15', 'fore_sd_15', 'analy', 'analy_sd'] # \n",
    "# to_plot = ['fore_15', 'advected_15']\n",
    "error_stats[to_plot].dropna().plot(marker='.')\n",
    "plt.ylim([0, ymax])\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Clear Sky Index')\n",
    "plt.title('Forecast Horizon of 15 minutes')\n",
    "# plt.legend(['Forecast RMSE', 'Smoothed WRF RMSE', 'Forecast sd', 'Analysis RMSE', 'Analysis sd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ymax=None\n",
    "# to_plot = ['fore_15', 'advected_15', 'fore_sd_15', 'analy', 'analy_sd'] # \n",
    "to_plot = ['fore_wind_sd_15', 'analy_wind_sd']\n",
    "error_stats[to_plot].dropna().plot(marker='.')\n",
    "plt.ylim([0, ymax])\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Clear Sky Index')\n",
    "plt.title('Forecast Horizon of 15 minutes')\n",
    "# plt.legend(['Forecast RMSE', 'Smoothed WRF RMSE', 'Forecast sd', 'Analysis RMSE', 'Analysis sd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vmax = None\n",
    "vmin = None\n",
    "for this_time in range(forecast_15.index.size):\n",
    "#     plt.figure()\n",
    "#     im = plt.pcolormesh(\n",
    "#             forecast_15.iloc[this_time]\n",
    "#             .values[:U_crop_size].reshape(U_crop_shape), cmap='Greys')\n",
    "#     plt.colorbar(im)\n",
    "\n",
    "    plt.figure()\n",
    "    im = plt.pcolormesh(\n",
    "        forecast_15.iloc[this_time]\n",
    "        .values[U_crop_size: U_crop_size + V_crop_size]\n",
    "        .reshape(V_crop_shape), cmap='Greys', vmax=vmax, vmin=vmin)\n",
    "    plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "this_time = '2014-05-29 10:15'\n",
    "plt.figure()\n",
    "im = plt.pcolormesh(\n",
    "        forecast_15.loc[this_time]\n",
    "        .values[wind_size:].reshape(crop_shape), cmap='Blues',\n",
    ")#vmin=0, vmax=1)\n",
    "plt.colorbar(im)\n",
    "\n",
    "plt.figure()\n",
    "im = plt.pcolormesh(\n",
    "        advected_15.loc[this_time]\n",
    "        .values.reshape(crop_shape), cmap='Blues',\n",
    ")#vmin=0, vmax=1)\n",
    "plt.colorbar(im)\n",
    "\n",
    "plt.figure()\n",
    "im = plt.pcolormesh(\n",
    "        csi_crop.loc[this_time]\n",
    "        .values.reshape(crop_shape), cmap='Blues')\n",
    "plt.colorbar(im)\n",
    "\n",
    "plt.figure()\n",
    "im = plt.pcolormesh(\n",
    "        forecast_15.loc[this_time]\n",
    "        .values[:U_crop_size].reshape(U_crop_shape), cmap='Greys')\n",
    "plt.colorbar(im)\n",
    "\n",
    "plt.figure()\n",
    "im = plt.pcolormesh(\n",
    "        forecast_15.loc[this_time]\n",
    "        .values[U_crop_size: U_crop_size + V_crop_size].reshape(V_crop_shape), cmap='Greys')\n",
    "plt.colorbar(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_time = '2014-05-29 12:45:00-07:00'\n",
    "this = ensemble_15.loc[this_time].values.reshape(ens_shape).mean(axis=1)\n",
    "this_U = this[:U_crop_size].reshape(U_crop_shape)\n",
    "this_V = this[U_crop_size:U_crop_size + V_crop_size].reshape(V_crop_shape)\n",
    "this_csi = this[U_crop_size + V_crop_size:].reshape(crop_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.pcolormesh(this_csi, cmap='Blues', vmin=0, vmax=1)\n",
    "\n",
    "plt.figure()\n",
    "plt.pcolormesh(csi_crop.loc[this_time].values.reshape(crop_shape),\n",
    "               cmap='Blues', vmin=0, vmax=1)\n",
    "\n",
    "# vmax = 30\n",
    "# plt.figure()\n",
    "# plt.pcolormesh(this_U, vmin=-vmax, vmax=vmax)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.pcolormesh(this_V, vmin=-vmax, vmax=vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vmin = 0\n",
    "vmax = 1\n",
    "nc = 11\n",
    "bounds = np.linspace(vmin, vmax, nc)\n",
    "norm = colors.BoundaryNorm(boundaries=bounds, ncolors=256)\n",
    "count=0\n",
    "dpi = 100\n",
    "for this_time in ensemble_movie.index:\n",
    "    mean = ensemble_movie.loc[this_time].values.reshape(ens_shape)\n",
    "    member1 = mean[2:, 0].reshape(crop_shape)\n",
    "    member2 = mean[2:, 1].reshape(crop_shape)\n",
    "    member3 = mean[2:, 2].reshape(crop_shape)\n",
    "    mean = mean.mean(axis=1)[2:]\n",
    "    mean = mean.reshape(crop_shape)\n",
    "    \n",
    "    plt.figure()\n",
    "    im = plt.pcolormesh(mean, cmap='Blues', norm=norm)\n",
    "    plt.colorbar(im, label='CSI')\n",
    "    plt.xlim([100, None])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.savefig('./movies/ens_mean_movie/zfig{0:04}.png'.format(count),\n",
    "               format='png', dpi=dpi)\n",
    "    count += 1\n",
    "#     plt.close('all')\n",
    "    \n",
    "#     plt.figure()\n",
    "#     im = plt.pcolormesh(member3, cmap='Blues', norm=norm)\n",
    "#     plt.colorbar(im, label='CSI')\n",
    "#     plt.xlim([100, None])\n",
    "#     plt.axis('off')\n",
    "    \n",
    "\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.pcolormesh(member1, cmap='Blues', vmin=0, vmax=1)\n",
    "#     plt.xlim([100, None])\n",
    "#     plt.title(this_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tmh_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(tmh_plot)\n",
    "\n",
    "vmin = 0\n",
    "vmax = 1\n",
    "nc = 15\n",
    "bounds = np.linspace(vmin, vmax, nc)\n",
    "norm = colors.BoundaryNorm(boundaries=bounds, ncolors=256)\n",
    "count=0\n",
    "dpi = 100\n",
    "for this_time in ensemble_movie.index:\n",
    "    this_ensemble = ensemble_movie.loc[this_time].reshape(ens_shape)[2:]\n",
    "    # this_other = [clouds.ravel()]\n",
    "    # other_titles = ['Original']\n",
    "    this_other = []\n",
    "    other_titles = []\n",
    "    nrows = 2\n",
    "    ncols = 2\n",
    "    adjust = .82\n",
    "    fig, ax = tmh_plot.ensemble_stamps(others=this_other, other_titles=other_titles,\n",
    "                             ensemble=this_ensemble, nrows=nrows,\n",
    "                             ncols=ncols, domain_shape=crop_shape, adjust=adjust)\n",
    "    fig.savefig('./movies/ens_movie/zfig{0:04}.png'.format(count),\n",
    "                format='png', dpi=dpi)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "this_time = '2014-05-29 12:15'\n",
    "that_time = '2014-05-29 12:00'\n",
    "plt.figure()\n",
    "im = plt.pcolormesh(\n",
    "        forecast_15.loc[that_time]\n",
    "        .values[:U_crop_size].reshape(U_crop_shape), cmap='Greys')\n",
    "plt.colorbar(im)\n",
    "\n",
    "plt.figure()\n",
    "im = plt.pcolormesh(\n",
    "        forecast_15.loc[this_time]\n",
    "        .values[:U_crop_size].reshape(U_crop_shape), cmap='Greys')\n",
    "plt.colorbar(im)\n",
    "\n",
    "plt.figure()\n",
    "im = plt.pcolormesh(\n",
    "        forecast_15.loc[that_time]\n",
    "        .values[U_crop_size: U_crop_size + V_crop_size].reshape(V_crop_shape), cmap='Greys')\n",
    "plt.colorbar(im)\n",
    "\n",
    "plt.figure()\n",
    "im = plt.pcolormesh(\n",
    "        forecast_15.loc[this_time]\n",
    "        .values[U_crop_size: U_crop_size + V_crop_size].reshape(V_crop_shape), cmap='Greys')\n",
    "plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ORIGINAL\n",
    "#%%timeit -n1 -r1\n",
    "## Assimilation only of sat to sat\n",
    "time0 = time.time()\n",
    "## Try to use a seperate sigma for wind assimilation\n",
    "importlib.reload(lf)\n",
    "dx = 250 #in km\n",
    "dy = 250 #in km\n",
    "C_max = 0.7\n",
    "assimilation_grid_size = 5 #was 1\n",
    "localization_letkf = 2*4\n",
    "sat_inflation = 1.5\n",
    "wind_inflation = 4\n",
    "wind_sat_sig = 1\n",
    "\n",
    "goes15_azimuth = 220.5\n",
    "goes15_elevation = 44.1\n",
    "\n",
    "sat_sig = 0.05 #0.01 <- sd<rmse\n",
    "ens_size = 38 #was 40\n",
    "wind_sigma = (1.8, 1.8) #(1.5, 1.5)\n",
    "wind_size = 2\n",
    "CI_sigma = .2\n",
    "\n",
    "pert_sigma = 0.12/3 # 0.10/3\n",
    "pert_mean = 0 # -0.02/3 # 0, 0.05, 0.01\n",
    "edge_weight = 1\n",
    "\n",
    "# works: const - 3 (2, 2) .2, 0.01, loc: 1\n",
    "# start_time = None\n",
    "# end_time = None\n",
    "start_time = '2014-05-29 14:00:00' #11:00:00 is not a bad start\n",
    "end_time = '2014-05-29 15:00:00' #Gets boring shortly after 14:00:00\n",
    "\n",
    "# U_corrected = U_const # - 3\n",
    "# V_corrected = V_const\n",
    "\n",
    "U_corrected = U_crop\n",
    "V_corrected = V_crop\n",
    "\n",
    "returned = lf.main_only_sat(\n",
    "    sat=csi_crop, x=x_crop, y=y_crop, domain_shape=crop_shape,                                                                                                                                                    \n",
    "    U=U_corrected, U_shape=U_crop_shape, V=V_corrected, V_shape=V_crop_shape,                                                                                                                                                            \n",
    "    start_time=start_time, end_time=end_time, dx=dx, dy=dy, C_max=C_max,                                                                                                                                               \n",
    "    assimilation_grid_size=assimilation_grid_size,                                                                                                                                                            \n",
    "    localization_letkf=localization_letkf, sat_inflation=sat_inflation,                                                                                                                                                \n",
    "    sat_sig=sat_sig, ens_size=ens_size,                                                                                                                                                                 \n",
    "    wind_sigma=wind_sigma, wind_size=wind_size,\n",
    "    CI_sigma=CI_sigma,\n",
    "    client=client, flat_error_domain=flat_error_domain,\n",
    "    wind_inflation=wind_inflation,\n",
    "    wind_sat_sig=wind_sat_sig,\n",
    "    pert_sigma=pert_sigma, pert_mean=pert_mean,\n",
    "    rf_eig=e, rf_vectors=v, rf_approx_var=approx_var,\n",
    "    edge_weight=edge_weight)\n",
    "ensemble_15, ensemble_30, ensemble_45 = returned[0:3]\n",
    "ensemble_analy, ens_shape = returned[3:5]\n",
    "advected_15, advected_30, advected_45 = returned[5:8]\n",
    "\n",
    "time1 = time.time()\n",
    "print('It took: ' + str((time1 - time0)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('It took: ' + str((time1 - time0)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.pcolormesh(advected_15.iloc[1].values[flat_error_domain].reshape(error_domain_shape), cmap='Blues')\n",
    "\n",
    "plt.figure()\n",
    "plt.pcolormesh(advected_30.iloc[1].values[flat_error_domain].reshape(error_domain_shape), cmap='Blues')\n",
    "\n",
    "plt.figure()\n",
    "plt.pcolormesh(advected_45.iloc[1].values[flat_error_domain].reshape(error_domain_shape), cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = '_{month}_{day}'.format(month=month, day=day)\n",
    "file = './data/for' + suffix + '/' + 'results_pert/'\n",
    "if not os.path.exists(file):\n",
    "    os.mkdir(file)\n",
    "file = file + '{var}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_15.to_hdf(file.format(var='ensemble_15.h5'), 'ensemble_15')\n",
    "ensemble_30.to_hdf(file.format(var='ensemble_30.h5'), 'ensemble_30')\n",
    "ensemble_45.to_hdf(file.format(var='ensemble_45.h5'), 'ensemble_45')\n",
    "ensemble_analy.to_hdf(file.format(var='ensemble_analy.h5'), 'ensemble_analy')\n",
    "advected_15.to_hdf(file.format(var='advected_15.h5'), 'advected_15')\n",
    "advected_30.to_hdf(file.format(var='advected_30.h5'), 'advected_30')\n",
    "advected_45.to_hdf(file.format(var='advected_45.h5'), 'advected_45')\n",
    "np.save(file.format(var='ens_shape'), ens_shape)\n",
    "np.save(file.format(var='flat_crop_indicies'), flat_crop_indicies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
